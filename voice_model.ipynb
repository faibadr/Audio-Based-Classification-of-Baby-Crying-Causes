{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24eabbe1-b7b6-4e1b-99cf-d202a1a71017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import noisereduce as nr\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28145edc-144a-4101-b62c-321b94fbf2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install noisereduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1496867-691d-43f0-8f69-0c643d8393da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for audio augmentation\n",
    "def augment_audio(y, sr):\n",
    "    pitch_shifted = librosa.effects.pitch_shift(y, sr=sr, n_steps=2)\n",
    "    time_stretched = librosa.effects.time_stretch(y, rate=0.8)\n",
    "    return [pitch_shifted, time_stretched]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940cfead-678d-4448-ad33-55658413ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data directory\n",
    "data_dir = 'data//my//'  \n",
    "n_mfcc = 13\n",
    "desired_labels = ['hungry', 'sad', 'uncomfortable']\n",
    "\n",
    "# Initialize lists for storing data and file paths\n",
    "X, labels, file_paths = [], [], []\n",
    "\n",
    "# Load and preprocess the audio files\n",
    "for label in desired_labels:\n",
    "    class_dir = os.path.join(data_dir, label)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        file_path = os.path.join(class_dir, filename)\n",
    "        y, sr = librosa.load(file_path, sr=16000)\n",
    "\n",
    "        # Noise reduction\n",
    "        y = nr.reduce_noise(y=y, sr=sr)\n",
    "\n",
    "        # Silence removal\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "\n",
    "        # Original and augmented audio processing\n",
    "        for y_processed in [y] + augment_audio(y, sr):\n",
    "            mfccs = librosa.feature.mfcc(y=y_processed, sr=sr, n_mfcc=n_mfcc)\n",
    "            X.append(mfccs.T)\n",
    "            labels.append(label)\n",
    "            file_paths.append(file_path)  # Append the file path here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e6e671-ad7f-4eed-86b8-e2854d119d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X:  12015\n",
      "Length of labels:  12015\n",
      "Length of file_paths:  12015\n"
     ]
    }
   ],
   "source": [
    "# Now, the lengths of X, labels, and file_paths should match\n",
    "print(\"Length of X: \", len(X))\n",
    "print(\"Length of labels: \", len(labels))\n",
    "print(\"Length of file_paths: \", len(file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae18c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum length of the MFCC arrays\n",
    "max_length = max(mfcc.shape[0] for mfcc in X)\n",
    "\n",
    "# Pad each MFCC array to have the same length\n",
    "X_padded = np.array([np.pad(mfcc, ((0, max_length - mfcc.shape[0]), (0, 0)), mode='constant') for mfcc in X])\n",
    "\n",
    "# Convert to NumPy array and encode labels\n",
    "X = np.array(X_padded)\n",
    "labels_encoded = LabelEncoder().fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1782ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, labels_categorical, test_size=0.4, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2514163c-2d74-4053-8253-a6dad22763ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to include a channel dimension for CNN input\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf5de892-2fcc-44ae-bcac-db3c4a7233d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (2, 2), activation='relu', input_shape=X_train.shape[1:]),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (2, 2), activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45024e1e-3a40-4513-8163-45345d326686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.4407 - loss: 7.0511 - val_accuracy: 0.7013 - val_loss: 0.7522\n",
      "Epoch 2/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.5991 - loss: 0.7840 - val_accuracy: 0.7221 - val_loss: 0.6564\n",
      "Epoch 3/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.6634 - loss: 0.7065 - val_accuracy: 0.7540 - val_loss: 0.5844\n",
      "Epoch 4/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.6893 - loss: 0.6665 - val_accuracy: 0.7827 - val_loss: 0.5229\n",
      "Epoch 5/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.7314 - loss: 0.6040 - val_accuracy: 0.7915 - val_loss: 0.5195\n",
      "Epoch 6/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7340 - loss: 0.5657 - val_accuracy: 0.7748 - val_loss: 0.5239\n",
      "Epoch 7/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7421 - loss: 0.5477 - val_accuracy: 0.8017 - val_loss: 0.4854\n",
      "Epoch 8/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.7589 - loss: 0.5293 - val_accuracy: 0.8104 - val_loss: 0.4730\n",
      "Epoch 9/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.7805 - loss: 0.4991 - val_accuracy: 0.8095 - val_loss: 0.4624\n",
      "Epoch 10/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.7959 - loss: 0.4543 - val_accuracy: 0.8215 - val_loss: 0.4576\n",
      "Epoch 11/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.7900 - loss: 0.4669 - val_accuracy: 0.8266 - val_loss: 0.4320\n",
      "Epoch 12/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.8166 - loss: 0.4185 - val_accuracy: 0.8345 - val_loss: 0.4301\n",
      "Epoch 13/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.8232 - loss: 0.4131 - val_accuracy: 0.8234 - val_loss: 0.4664\n",
      "Epoch 14/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8360 - loss: 0.3885 - val_accuracy: 0.8387 - val_loss: 0.4047\n",
      "Epoch 15/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8468 - loss: 0.3729 - val_accuracy: 0.8465 - val_loss: 0.3996\n",
      "Epoch 16/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8579 - loss: 0.3462 - val_accuracy: 0.8447 - val_loss: 0.4166\n",
      "Epoch 17/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8476 - loss: 0.3636 - val_accuracy: 0.8423 - val_loss: 0.4217\n",
      "Epoch 18/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8560 - loss: 0.3393 - val_accuracy: 0.8507 - val_loss: 0.4019\n",
      "Epoch 19/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8571 - loss: 0.3458 - val_accuracy: 0.8456 - val_loss: 0.4497\n",
      "Epoch 20/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8602 - loss: 0.3255 - val_accuracy: 0.8622 - val_loss: 0.3931\n",
      "Epoch 21/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.8668 - loss: 0.3099 - val_accuracy: 0.8645 - val_loss: 0.4016\n",
      "Epoch 22/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8854 - loss: 0.2822 - val_accuracy: 0.8581 - val_loss: 0.3842\n",
      "Epoch 23/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.8711 - loss: 0.3042 - val_accuracy: 0.8738 - val_loss: 0.3799\n",
      "Epoch 24/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.8883 - loss: 0.2732 - val_accuracy: 0.8682 - val_loss: 0.3871\n",
      "Epoch 25/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.8812 - loss: 0.2832 - val_accuracy: 0.8664 - val_loss: 0.4013\n",
      "Epoch 26/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.8836 - loss: 0.2915 - val_accuracy: 0.8650 - val_loss: 0.4058\n",
      "Epoch 27/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.8903 - loss: 0.2734 - val_accuracy: 0.8650 - val_loss: 0.4276\n",
      "Epoch 28/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.8869 - loss: 0.2763 - val_accuracy: 0.8733 - val_loss: 0.3859\n",
      "Epoch 29/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.8986 - loss: 0.2586 - val_accuracy: 0.8687 - val_loss: 0.4272\n",
      "Epoch 30/30\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9010 - loss: 0.2535 - val_accuracy: 0.8618 - val_loss: 0.4060\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.3, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "767ff143-e514-454b-9097-1b536cded8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 - 1s - 4ms/step - accuracy: 0.8612 - loss: 0.4382\n",
      "test Accuracy:  0.8612151741981506\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"test Accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec701b6-4b38-4bff-9405-798a19d82a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c6a069-d6db-4cb4-b044-8cbb52a3af96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       hungry       0.87      0.80      0.84      1613\n",
      "          sad       0.99      0.86      0.92      1615\n",
      "uncomfortable       0.76      0.92      0.84      1578\n",
      "\n",
      "     accuracy                           0.86      4806\n",
      "    macro avg       0.87      0.86      0.86      4806\n",
      " weighted avg       0.87      0.86      0.86      4806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print the classification report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_test_classes, y_pred_classes, target_names=['hungry', 'sad', 'uncomfortable'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2cf0b-70bd-4d2d-a48c-a1db6be3cd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963b837-e0a6-479c-a364-26d3001053c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18eec1-31a7-4787-9f52-dee1da0e2d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4b3c9-5fe7-47cd-9af8-d1062bb60bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75962566-9d74-4462-a516-c59ce2891fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968d4a0-6198-40b3-bbc9-eef53413ec9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7060fb-3938-48ac-a530-68b73ce1e665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0ed48-98fd-4f01-a0d5-b1954c2e6c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984f6c5-1058-407b-9069-4625550f66f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a340cc6c-1c27-4a8d-80c6-1c1ced45cb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a82f9b-dd05-4671-a81e-1b9ed0f0bd98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fad0e3-0a22-45b7-92e0-a3568efed4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a277cbe7-24fd-4623-8aac-1c2b0b6277da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2ee3a-8dd5-4d5c-8917-1a819f26335d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d34182-82d0-4f3c-9a8c-f6d126010922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47795933-18d3-454c-a19f-eca4a969cca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
